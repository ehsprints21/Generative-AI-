{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The data is taken from kaggle using the following link : https://www.kaggle.com/datasets/jcprogjava/handwritten-digits-dataset-not-in-mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Hlia14jJlb",
        "outputId": "fa2a07ef-dcf5-4e2e-8546-ce632c4ef408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting potracer\n",
            "  Downloading potracer-0.0.4-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from potracer) (1.25.2)\n",
            "Installing collected packages: potracer\n",
            "Successfully installed potracer-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install potracer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mYtZe_S5LhKs"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import potrace\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fZUT3vLQZcqO"
      },
      "outputs": [],
      "source": [
        "# Function to get SVG path of a raster image\n",
        "def get_vector(filename, nudge = 0.33, bilateral_filter=True, use_l2_gradient=True):\n",
        "    # Read the image in RGBA mode\n",
        "    image = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
        "    alpha_channel = image[:, :, 3]\n",
        "    # Set all non-zero alpha pixels to the specified value\n",
        "    alpha_channel[alpha_channel > 180] = 255  # White\n",
        "    alpha_channel[alpha_channel <= 180] = 0\n",
        "    # Create a new image where only the alpha channel is used for edge detection\n",
        "    bitmap = potrace.Bitmap(alpha_channel)\n",
        "    path = bitmap.trace(turdsize=1, turnpolicy=potrace.POTRACE_TURNPOLICY_MINORITY, alphamax=1, opticurve=0, opttolerance=0.2)\n",
        "    # Generate SVG path data\n",
        "    svg_path_data = []\n",
        "    for curve in path.curves:\n",
        "        segments = curve.segments\n",
        "        start = curve.start_point\n",
        "        d = f'M {start.x},{start.y} '  # Move to the start point\n",
        "        for segment in segments:\n",
        "            if segment.is_corner:\n",
        "                x1, y1 = segment.c.x, segment.c.y\n",
        "                x2, y2 = segment.end_point.x, segment.end_point.y\n",
        "                d += f'L {x1},{y1} {x2},{y2} '  # Line to the control and end point\n",
        "            else:\n",
        "                x1, y1 = segment.c1.x, segment.c1.y\n",
        "                x2, y2 = segment.c2.x, segment.c2.y\n",
        "                x3, y3 = segment.end_point.x, segment.end_point.y\n",
        "                d += f'C {x1},{y1} {x2},{y2} {x3},{y3} '  # Cubic Bezier curve to the control and end points\n",
        "            start = segment.end_point\n",
        "        svg_path_data.append(d.strip())\n",
        "    return svg_path_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ePa3Oz7oi_xC"
      },
      "outputs": [],
      "source": [
        "# Function to get a .svg file from the path\n",
        "def create_svg_file(svg_paths, filename, width=500, height=500):\n",
        "    # Create the root element\n",
        "    svg = ET.Element('svg', xmlns=\"http://www.w3.org/2000/svg\", version=\"1.1\", width=str(width), height=str(height))\n",
        "\n",
        "    # Add each path to the SVG\n",
        "    for path_data in svg_paths:\n",
        "        path = ET.SubElement(svg, 'path', d=path_data, fill=\"none\", stroke=\"black\", stroke_width=\"1\")\n",
        "\n",
        "    # Create the tree structure and write to file\n",
        "    tree = ET.ElementTree(svg)\n",
        "    tree.write(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mdhkvbnLfED",
        "outputId": "f106438f-1763-4e5a-a988-d25dde649c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files extracted to /content/unzipped_archive/\n"
          ]
        }
      ],
      "source": [
        "zip_file_name = '/content/drive/MyDrive/archive.zip'  # Change this to the name of your ZIP file if different\n",
        "unzip_dir = '/content/unzipped_archive/'  # Extract to your local environment\n",
        "\n",
        "os.makedirs(unzip_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_dir)\n",
        "\n",
        "print(f'Files extracted to {unzip_dir}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "73m3byG4ZCnT"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    vectors = []\n",
        "    for label in os.listdir(folder_path):\n",
        "        label_path = os.path.join(folder_path, label)\n",
        "        if os.path.isdir(label_path):\n",
        "            for subfolder in os.listdir(label_path):\n",
        "                subfolder_path = os.path.join(label_path, subfolder)\n",
        "                if os.path.isdir(subfolder_path):\n",
        "                    for image_file in glob.glob(os.path.join(subfolder_path, '*.png')):\n",
        "                        try:\n",
        "                            images.append(image_file)\n",
        "                            labels.append(label)\n",
        "                            vectors.append(get_vector(image_file))\n",
        "                        except Exception as e:\n",
        "                            print(f'Error loading image {image_file}: {e}')\n",
        "    return images, labels , vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SWorRVkAZESU"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset folder\n",
        "dataset_path = os.path.join(unzip_dir, '/content/unzipped_archive/dataset')\n",
        "images, labels, vectors = load_images_from_folder(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "weeJdnzuZV1a"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'image': images,\n",
        "    'label': labels,\n",
        "    'vector': vectors\n",
        "})\n",
        "df = df.sort_values(by=['label']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bfWZ3zLxvyRl"
      },
      "outputs": [],
      "source": [
        "# Commands\n",
        "commands = ['M', 'L', 'C']\n",
        "commands_dict = {cmd: idx for idx, cmd in enumerate(commands)}\n",
        "\n",
        "# Tokenize SVG paths\n",
        "def tokenize_svg_path(svg_path):\n",
        "    tokens = []\n",
        "    for path in svg_path:\n",
        "        parts = path.split()\n",
        "        i = 0\n",
        "        while i < len(parts):\n",
        "            command = parts[i]\n",
        "            i += 1\n",
        "            if command == 'M':\n",
        "                tokens.append((command, parts[i]))\n",
        "                i += 1\n",
        "            elif command == 'L':\n",
        "                for _ in range(2):\n",
        "                    tokens.append((command, parts[i]))\n",
        "                    i += 1\n",
        "            elif command == 'C':\n",
        "                for _ in range(3):\n",
        "                    tokens.append((command, parts[i]))\n",
        "                    i += 1\n",
        "    return tokens\n",
        "\n",
        "# Separate commands and coordinates\n",
        "def separate_tokens(tokens):\n",
        "    command_tokens = [t[0] for t in tokens]\n",
        "    coordinate_tokens = [t[1] for t in tokens]\n",
        "    return command_tokens, coordinate_tokens\n",
        "\n",
        "# Encode commands\n",
        "def encode_commands(command_tokens):\n",
        "    command_indices = [commands_dict[cmd] for cmd in command_tokens]\n",
        "    return tf.constant(command_indices, dtype=tf.int32)\n",
        "\n",
        "# Convert coordinates to floats and pad\n",
        "def process_coordinates(coordinate_tokens):\n",
        "    coordinate_floats = []\n",
        "    for coord in coordinate_tokens:\n",
        "        coords = coord.split(',')\n",
        "        if len(coords) == 2:\n",
        "            try:\n",
        "                x, y = map(float, coords)\n",
        "                coordinate_floats.append([x, y])\n",
        "            except ValueError as e:\n",
        "                print(f\"Error parsing coordinates '{coord}': {e}\")\n",
        "        elif len(coords) == 4:\n",
        "            try:\n",
        "                coords = list(map(float, coords))\n",
        "                for i in range(0, len(coords), 2):\n",
        "                    coordinate_floats.append([coords[i], coords[i+1]])\n",
        "            except ValueError as e:\n",
        "                print(f\"Error parsing coordinates '{coord}': {e}\")\n",
        "        elif len(coords) == 6:\n",
        "            try:\n",
        "                coords = list(map(float, coords))\n",
        "                for i in range(0, len(coords), 2):\n",
        "                    coordinate_floats.append([coords[i], coords[i+1]])\n",
        "            except ValueError as e:\n",
        "                print(f\"Error parsing coordinates '{coord}': {e}\")\n",
        "        else:\n",
        "            print(f\"Unexpected number of coordinates in '{coord}'\")\n",
        "\n",
        "    # Convert to numpy array\n",
        "    if coordinate_floats:\n",
        "        coordinate_array = np.array(coordinate_floats)\n",
        "    else:\n",
        "        coordinate_array = np.empty((0, 2))\n",
        "\n",
        "    return coordinate_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yXNmNJzd6MQQ"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(commands)\n",
        "embedding_dim = 2\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rIlGapf_0eQ3"
      },
      "outputs": [],
      "source": [
        "# Padding the data to feed transformer\n",
        "def process_svg_paths(df):\n",
        "    combined_sequences = []\n",
        "    max_sequence_length = 0\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        path = row['vector']\n",
        "        tokens = tokenize_svg_path(path)\n",
        "        command_tokens, coordinate_tokens = separate_tokens(tokens)\n",
        "        if len(command_tokens) == 0:\n",
        "            print(row)\n",
        "        command_indices = encode_commands(command_tokens)\n",
        "        command_embeddings = embedding_layer(command_indices)\n",
        "        coordinate_array = process_coordinates(coordinate_tokens)\n",
        "\n",
        "        sequence_length = len(command_tokens)\n",
        "        max_sequence_length = max(max_sequence_length, sequence_length)\n",
        "\n",
        "        combined_sequences.append((command_embeddings, coordinate_array))\n",
        "\n",
        "    padded_sequences = []\n",
        "    for command_embeddings, coordinate_array in combined_sequences:\n",
        "        command_pad_length = max_sequence_length - tf.shape(command_embeddings)[0]\n",
        "        coordinate_pad_length = max_sequence_length - coordinate_array.shape[0]\n",
        "\n",
        "        if command_pad_length > 0:\n",
        "            command_embeddings_padded = tf.pad(command_embeddings, [[0, command_pad_length], [0, 0]])\n",
        "        else:\n",
        "            command_embeddings_padded = command_embeddings\n",
        "\n",
        "        if coordinate_array.ndim == 1:\n",
        "            coordinate_array = np.expand_dims(coordinate_array, axis=0)\n",
        "        if coordinate_pad_length > 0:\n",
        "            coordinate_array_padded = np.pad(coordinate_array, ((0, coordinate_pad_length), (0, 0)), 'constant')\n",
        "        else:\n",
        "            coordinate_array_padded = coordinate_array\n",
        "\n",
        "        coordinate_array_padded_tensor = tf.convert_to_tensor(coordinate_array_padded, dtype=tf.float32)\n",
        "\n",
        "        if command_embeddings_padded.shape[0] != coordinate_array_padded_tensor.shape[0]:\n",
        "            print(f\"Shape mismatch found: command_embeddings_padded shape: {command_embeddings_padded.shape}, coordinate_array_padded_tensor shape: {coordinate_array_padded_tensor.shape}\")\n",
        "            continue  # Skip this data point\n",
        "\n",
        "        try:\n",
        "            combined_sequence = tf.concat([command_embeddings_padded, coordinate_array_padded_tensor], axis=1)\n",
        "            padded_sequences.append(combined_sequence)\n",
        "        except Exception as e:\n",
        "            print(f\"Error concatenating tensors: {e}\")\n",
        "            print(f\"command_embeddings_padded shape: {command_embeddings_padded.shape}\")\n",
        "            print(f\"coordinate_array_padded_tensor shape: {coordinate_array_padded_tensor.shape}\")\n",
        "\n",
        "    return padded_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiUBvEKD9-1F",
        "outputId": "561571fb-4312-4d00-d6ef-70ef23142165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 68947\n",
            "Validation set size: 17237\n",
            "Test set size: 21546\n"
          ]
        }
      ],
      "source": [
        "# Split the data\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ais2l6xH4clH"
      },
      "outputs": [],
      "source": [
        "def prepare_data(df):\n",
        "    max_sequence_length = 90\n",
        "    sequences = process_svg_paths(df)\n",
        "    padded_sequences = [\n",
        "        tf.pad(seq, [[0, max_sequence_length - tf.shape(seq)[0]], [0, 0]])\n",
        "        for seq in sequences\n",
        "    ]\n",
        "    padded_sequences = tf.stack(padded_sequences)\n",
        "    labels = df['label'].values\n",
        "    return padded_sequences, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "foR1D0Ikd1LB"
      },
      "outputs": [],
      "source": [
        "# Prepare training, validation, and test data\n",
        "train_sequences, train_labels = prepare_data(train_df)\n",
        "val_sequences, val_labels = prepare_data(val_df)\n",
        "test_sequences, test_labels = prepare_data(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jMmn-wz-XInP"
      },
      "outputs": [],
      "source": [
        "# prompt: datatype of train_sequences\n",
        "train_labels = train_labels.astype('int32')\n",
        "val_labels = val_labels.astype('int32')\n",
        "test_labels = test_labels.astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-v-o9EpWfA_M"
      },
      "outputs": [],
      "source": [
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = callbacks.ModelCheckpoint('detection_model.h5', save_best_only=True, monitor='val_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "30dNeAgUbk_g"
      },
      "outputs": [],
      "source": [
        "def create_transformer_model(input_shape, num_classes, num_heads=4, ff_dim=128, num_layers=2):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Positional Encoding\n",
        "    position_embedding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(tf.range(start=0, limit=input_shape[0], delta=1))\n",
        "    x = inputs + position_embedding\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        # Multi-head Self Attention\n",
        "        x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=input_shape[1])(x, x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        # Feed Forward Network\n",
        "        x_ff = layers.Dense(ff_dim, activation='relu')(x)\n",
        "        x_ff = layers.Dense(input_shape[1])(x_ff)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x + x_ff)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SGZ7AKIgd2Tw"
      },
      "outputs": [],
      "source": [
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jpU_qXm72gXL"
      },
      "outputs": [],
      "source": [
        "# Example hyperparameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 16\n",
        "dropout_rate = 0.3\n",
        "input_shape = (90,4)\n",
        "num_classes = 10\n",
        "\n",
        "model = create_transformer_model(input_shape, num_classes)\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3nTbxIOeNFE",
        "outputId": "56e4e2b8-041b-4a3a-bd2d-dafade58f75d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4310/4310 [==============================] - 64s 13ms/step - loss: 1.4731 - accuracy: 0.4438 - val_loss: 1.2934 - val_accuracy: 0.5170 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "   6/4310 [..............................] - ETA: 44s - loss: 1.3488 - accuracy: 0.4792"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4310/4310 [==============================] - 55s 13ms/step - loss: 1.1962 - accuracy: 0.5466 - val_loss: 1.0821 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 1.0337 - accuracy: 0.6043 - val_loss: 0.8978 - val_accuracy: 0.6474 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.9334 - accuracy: 0.6424 - val_loss: 0.8373 - val_accuracy: 0.6786 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.8695 - accuracy: 0.6664 - val_loss: 0.8183 - val_accuracy: 0.6872 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.8130 - accuracy: 0.6886 - val_loss: 0.7432 - val_accuracy: 0.7049 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4310/4310 [==============================] - 61s 14ms/step - loss: 0.7771 - accuracy: 0.7030 - val_loss: 0.7618 - val_accuracy: 0.7021 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.7466 - accuracy: 0.7149 - val_loss: 0.6853 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.7260 - accuracy: 0.7242 - val_loss: 0.6815 - val_accuracy: 0.7427 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.7079 - accuracy: 0.7340 - val_loss: 0.7615 - val_accuracy: 0.6975 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.6925 - accuracy: 0.7405 - val_loss: 0.6182 - val_accuracy: 0.7654 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.6651 - accuracy: 0.7509 - val_loss: 0.6026 - val_accuracy: 0.7736 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.6562 - accuracy: 0.7555 - val_loss: 0.6329 - val_accuracy: 0.7606 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.6419 - accuracy: 0.7608 - val_loss: 0.5583 - val_accuracy: 0.7901 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.6312 - accuracy: 0.7651 - val_loss: 0.5878 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.6006 - accuracy: 0.7744 - val_loss: 0.5966 - val_accuracy: 0.7664 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.5814 - accuracy: 0.7839 - val_loss: 0.4795 - val_accuracy: 0.8204 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.5454 - accuracy: 0.8011 - val_loss: 0.4842 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.5097 - accuracy: 0.8120 - val_loss: 0.4280 - val_accuracy: 0.8408 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.4774 - accuracy: 0.8245 - val_loss: 0.4437 - val_accuracy: 0.8377 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "4310/4310 [==============================] - 60s 14ms/step - loss: 0.4521 - accuracy: 0.8354 - val_loss: 0.4649 - val_accuracy: 0.8251 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.4352 - accuracy: 0.8412 - val_loss: 0.3866 - val_accuracy: 0.8587 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.4237 - accuracy: 0.8461 - val_loss: 0.3335 - val_accuracy: 0.8768 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.4036 - accuracy: 0.8539 - val_loss: 0.4172 - val_accuracy: 0.8429 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.4045 - accuracy: 0.8543 - val_loss: 0.3836 - val_accuracy: 0.8579 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.3871 - accuracy: 0.8612 - val_loss: 0.5151 - val_accuracy: 0.8114 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.3792 - accuracy: 0.8629 - val_loss: 0.3321 - val_accuracy: 0.8771 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.3755 - accuracy: 0.8668 - val_loss: 0.5195 - val_accuracy: 0.8170 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.3681 - accuracy: 0.8691 - val_loss: 0.4585 - val_accuracy: 0.8411 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.3588 - accuracy: 0.8714 - val_loss: 0.3333 - val_accuracy: 0.8781 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.3570 - accuracy: 0.8740 - val_loss: 0.2988 - val_accuracy: 0.8920 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.3374 - accuracy: 0.8794 - val_loss: 0.3432 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "4310/4310 [==============================] - 60s 14ms/step - loss: 0.3299 - accuracy: 0.8841 - val_loss: 0.3008 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.3185 - accuracy: 0.8885 - val_loss: 0.3098 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.2988 - accuracy: 0.8987 - val_loss: 0.2670 - val_accuracy: 0.9049 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "4310/4310 [==============================] - 58s 13ms/step - loss: 0.2893 - accuracy: 0.9023 - val_loss: 0.2644 - val_accuracy: 0.9032 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.3008 - accuracy: 0.9028 - val_loss: 0.3268 - val_accuracy: 0.8906 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.2541 - accuracy: 0.9150 - val_loss: 0.2646 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.3997 - accuracy: 0.8772 - val_loss: 0.3723 - val_accuracy: 0.8752 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.2676 - accuracy: 0.9143 - val_loss: 0.2205 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.2479 - accuracy: 0.9208 - val_loss: 0.2380 - val_accuracy: 0.9180 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.2393 - accuracy: 0.9242 - val_loss: 0.1490 - val_accuracy: 0.9536 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.2219 - accuracy: 0.9291 - val_loss: 0.1743 - val_accuracy: 0.9421 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.2226 - accuracy: 0.9296 - val_loss: 0.2461 - val_accuracy: 0.9114 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "4310/4310 [==============================] - 56s 13ms/step - loss: 0.2234 - accuracy: 0.9293 - val_loss: 0.1521 - val_accuracy: 0.9502 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "4310/4310 [==============================] - 55s 13ms/step - loss: 0.2087 - accuracy: 0.9340 - val_loss: 0.2303 - val_accuracy: 0.9245 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.1984 - accuracy: 0.9366 - val_loss: 0.1792 - val_accuracy: 0.9370 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.1080 - accuracy: 0.9667 - val_loss: 0.0983 - val_accuracy: 0.9683 - lr: 2.0000e-04\n",
            "Epoch 49/50\n",
            "4310/4310 [==============================] - 62s 14ms/step - loss: 0.1054 - accuracy: 0.9678 - val_loss: 0.0925 - val_accuracy: 0.9698 - lr: 2.0000e-04\n",
            "Epoch 50/50\n",
            "4310/4310 [==============================] - 57s 13ms/step - loss: 0.1026 - accuracy: 0.9680 - val_loss: 0.1044 - val_accuracy: 0.9691 - lr: 2.0000e-04\n",
            "674/674 - 4s - loss: 0.1068 - accuracy: 0.9706 - 4s/epoch - 6ms/step\n",
            "Test accuracy: 0.9705745577812195\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_sequences, train_labels,\n",
        "                    validation_data=(val_sequences, val_labels),\n",
        "                    epochs=50,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_sequences, test_labels, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7rXPXNdBerPq"
      },
      "outputs": [],
      "source": [
        "model = models.load_model('detection_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4EXqJJ8PSpzx"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('digit_classifier_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ-Sj-A8DTGf"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_sequences)\n",
        "\n",
        "# Convert probabilities to label indices\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "test_df['predicted_label'] = predicted_labels\n",
        "\n",
        "# Display the updated test_df\n",
        "print(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMQeAgIVXFyA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
